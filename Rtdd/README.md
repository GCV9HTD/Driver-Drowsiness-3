# [Real-time Driver Drowsiness Detection for Embedded System Using Model Compression of Deep Neural Networks](http://openaccess.thecvf.com/content_cvpr_2017_workshops/w4/papers/Reddy_Real-Time_Driver_Drowsiness_CVPR_2017_paper.pdf)

## Summary
### Introduction
In this paper, a novel approach towards real-time drowsiness detection based on deep learning which can be implemented on a low cost embedded board and performs with a high accuracy is proposed. Techniques use to measure driver drowsiness can be broadly classified into 3 categories
* Driving pattern of the vehicle
* Psychophysiological characteristics of drivers
* Computer Vision techniques for driver monitoring 

First Category is based on monitoring steering, wheel movement, acceleration or breaking time series, lane departure to determine the level of drowsiness. However, the driving pattern-based techniques are highly dependent on driving skills, road conditions and vehicle characteristics. The second class of techniques uses data taken from physiological sensors, like EEG, ECG and EOG data. EEG signals contain information about the brain’s activity. Three main signals in EEG for measuring driver’s drowsiness are alpha, delta and theta signals. When a driver is drowsy, delta and theta signals spikes up, alpha signal increasing slightly. However, the major drawback of this method is the intrusiveness which disturbs drivers by attaching many sensors on the body. The third class is based on Computer Vision techniques mainly concentrate on detecting eye closure, yawning patterns and the overall expression of the face and movement of the head. This paper presents a Computer Vision-based deep learning approach for driver drowsiness. This method takes the driver’s face as input and classifies the drowsiness behavior into 3 classes (normal, yawning and drowsy).

In real-time applications, performance in terms of speed is also a crucial point. it is a burden to deploy deep learning algorithms to practical applications on embedded systems since the model size of deep learning is generally large and high computational complexity is required. So knowledge distillation approach is used to reduce the size of the model. In knowledge distillation approach between two networks. A role of one is the teacher and that of the other network is the student. Teacher networks are large and have high computation requirements, which can learn patterns from a large dataset. On the contrary student, networks are small requiring less computation and can learn only from teacher network. Due to its smaller size, student network is suitable to be implemented on embedded devices and has the capability to run at real-time on portable devices.

### Architecture
The overall architecture consists of two steps in which the first step is the joint face detection and alignment and the second is the drowsiness detection model. For the face detection and alignment task, Multi-Task Cascaded Convolutional Networks (MTCCN) and Driver Drowsiness Detection Network (DDDN) is used for detecting driver’s drowsiness. Overall, there are three types of models
#### Baseline-4 Model
> In this network, the inputs are left-eye, right-eye, mouth and face obtained from the detection network. The input images are resized into the size of 224ⅹ224. The baseline-4 model is a neural network consisting 5 convolutional layers for each 4-stream input. Each stream of the network structure is similar to the AlexNet architecture with filter sizes of 11ⅹ11, 5ⅹ5, 3ⅹ3, 3ⅹ3 and 3ⅹ3. The convolution layers of eyes share the same weight. This was proposed because the features from the eyes will approximately be the same. Each stream of convolutional layers ends with fully connected (FC) layers. Each size of the FC layers is stated in the above figure. All the FC layers are connected to the last two FC layers.
#### Baseline-2 Model
> Instead of using four inputs as the baseline-4 model, the newly proposed baseline-2 model is a 2-stream network structure which takes two inputs, the cropped images of the left eye and the mouth, excluding the whole face from the set of inputs. 
#### Compressed-2 Model 
> This model adopts a compression using distillation of neural network. “Distillation” of a neural network refers to an approach transferring the knowledge from a superfluously huge model to a small model. This technique was introduced because it is difficult to train a small network directly from hard-classified labels since small networks don’t converge easily. Large networks can easily be trained on huge datasets with discrete, hard-classified labels. Instead of training discrete value outputs to the student network, the above paper trained soft-value outputs from the teacher network to student network. Since these soft-valued outputs will have more information about the input than discrete values, the smaller network can converge on the same dataset with fewer iterations and maintaining accuracy.

We finally predict 3 classes of outputs as described earlier, which are normal, yawning and drowsy. Normal means that the driver is conscious and not in any state of fatigue. Yawning indicates the driver might become in danger of drowsy driving in a short time. Drowsy means that driver is having severe drowsiness or fatigue condition and immediately needs to take rest.